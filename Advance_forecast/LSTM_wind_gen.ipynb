{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-07T13:19:23.273014Z",
     "start_time": "2025-12-07T13:19:22.854699Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print(os.getcwd())\n",
    "# Load the file\n",
    "df = pd.read_csv('../Gen_data/gen_hourly_MW_all.csv')\n",
    "ptype = \"Wind Onshore\"\n",
    "df = df[(df[\"Production Type\"] == ptype)].copy()\n",
    "df = df.rename(columns={\n",
    "    \"Generation (MW)\": \"Generation (MWh)\"\n",
    "})\n",
    "# Check the first few rows\n",
    "print(df.dtypes)\n",
    "df.head()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\202510\\2025-26-Data-driven\\Advance_forecast\n",
      "datetime             object\n",
      "Area                 object\n",
      "Production Type      object\n",
      "Generation (MWh)    float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                   datetime    Area Production Type  Generation (MWh)\n",
       "158144  2022-01-01 00:00:00  BZN|ES    Wind Onshore            6342.0\n",
       "158145  2022-01-01 01:00:00  BZN|ES    Wind Onshore            6398.0\n",
       "158146  2022-01-01 02:00:00  BZN|ES    Wind Onshore            6456.0\n",
       "158147  2022-01-01 03:00:00  BZN|ES    Wind Onshore            6144.0\n",
       "158148  2022-01-01 04:00:00  BZN|ES    Wind Onshore            5943.0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>Area</th>\n",
       "      <th>Production Type</th>\n",
       "      <th>Generation (MWh)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>158144</th>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>BZN|ES</td>\n",
       "      <td>Wind Onshore</td>\n",
       "      <td>6342.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158145</th>\n",
       "      <td>2022-01-01 01:00:00</td>\n",
       "      <td>BZN|ES</td>\n",
       "      <td>Wind Onshore</td>\n",
       "      <td>6398.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158146</th>\n",
       "      <td>2022-01-01 02:00:00</td>\n",
       "      <td>BZN|ES</td>\n",
       "      <td>Wind Onshore</td>\n",
       "      <td>6456.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158147</th>\n",
       "      <td>2022-01-01 03:00:00</td>\n",
       "      <td>BZN|ES</td>\n",
       "      <td>Wind Onshore</td>\n",
       "      <td>6144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158148</th>\n",
       "      <td>2022-01-01 04:00:00</td>\n",
       "      <td>BZN|ES</td>\n",
       "      <td>Wind Onshore</td>\n",
       "      <td>5943.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "57c3b68606553ef0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T13:19:23.293036Z",
     "start_time": "2025-12-07T13:19:23.278027Z"
    }
   },
   "source": [
    "# Convert datetime column to proper datetime format\n",
    "df['ds'] = pd.to_datetime(df['datetime'])\n",
    "\n",
    "# Rename the generation column for RandomForestModel (use the MWh column name)\n",
    "df['y'] = df['Generation (MWh)']\n",
    "\n",
    "# Keep only the necessary columns\n",
    "df = df[['ds', 'y']].sort_values('ds')\n",
    "\n",
    "print(df.dtypes)\n",
    "print(df.head())\n",
    "print(f\"\\nData range: {df['ds'].min()} to {df['ds'].max()}\")\n",
    "print(f\"Total records: {len(df)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ds    datetime64[ns]\n",
      "y            float64\n",
      "dtype: object\n",
      "                        ds       y\n",
      "158144 2022-01-01 00:00:00  6342.0\n",
      "158145 2022-01-01 01:00:00  6398.0\n",
      "158146 2022-01-01 02:00:00  6456.0\n",
      "158147 2022-01-01 03:00:00  6144.0\n",
      "158148 2022-01-01 04:00:00  5943.0\n",
      "\n",
      "Data range: 2022-01-01 00:00:00 to 2024-12-31 23:00:00\n",
      "Total records: 26301\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "9529cfac94247256",
   "metadata": {},
   "source": [
    "## Filter data 2022-24 3-9"
   ]
  },
  {
   "cell_type": "code",
   "id": "ec757831be75a1f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T13:19:23.325562Z",
     "start_time": "2025-12-07T13:19:23.300564Z"
    }
   },
   "source": [
    "# create new relevant variables or filters when useful\n",
    "df['ds'] = pd.to_datetime(df['ds'], format='%Y/%m/%d %H:%M:%S')\n",
    "df['year'] = df['ds'].dt.year\n",
    "df['month'] = df['ds'].dt.month\n",
    "df['day'] = df['ds'].dt.day\n",
    "df['weekday'] = df['ds'].dt.day_name()  # weekdays\n",
    "df['is_weekend'] = df['ds'].dt.dayofweek >= 5  # True = weekends\n",
    "df['season'] = df['ds'].dt.quarter  # season 1-4\n",
    "# def seasons function\n",
    "def get_season(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'Winter'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'Spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'Summer'\n",
    "    elif month in [9, 10, 11]:\n",
    "        return 'Autumn'\n",
    "\n",
    "# apply season\n",
    "df['season'] = df['month'].apply(get_season)\n",
    "\n",
    "df = df[(df['month'] >= 1) & (df['month'] <= 6)].copy()\n",
    "\n",
    "print(f\"Filtered data for March to September:\")\n",
    "print(f\"  Period: {df['ds'].min()} to {df['ds'].max()}\")\n",
    "print(f\"  Total records: {len(df)}\")\n",
    "print(f\"  Years covered: {sorted(df['year'].unique())}\")\n",
    "\n",
    "df[df['season'] == 'Summer'].head()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data for March to September:\n",
      "  Period: 2022-01-01 00:00:00 to 2024-06-30 23:00:00\n",
      "  Total records: 13053\n",
      "  Years covered: [2022, 2023, 2024]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                        ds       y  year  month  day    weekday  is_weekend  \\\n",
       "161767 2022-06-01 00:00:00  3090.0  2022      6    1  Wednesday       False   \n",
       "161768 2022-06-01 01:00:00  3297.0  2022      6    1  Wednesday       False   \n",
       "161769 2022-06-01 02:00:00  3487.0  2022      6    1  Wednesday       False   \n",
       "161770 2022-06-01 03:00:00  3693.0  2022      6    1  Wednesday       False   \n",
       "161771 2022-06-01 04:00:00  3694.0  2022      6    1  Wednesday       False   \n",
       "\n",
       "        season  \n",
       "161767  Summer  \n",
       "161768  Summer  \n",
       "161769  Summer  \n",
       "161770  Summer  \n",
       "161771  Summer  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>161767</th>\n",
       "      <td>2022-06-01 00:00:00</td>\n",
       "      <td>3090.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>False</td>\n",
       "      <td>Summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161768</th>\n",
       "      <td>2022-06-01 01:00:00</td>\n",
       "      <td>3297.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>False</td>\n",
       "      <td>Summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161769</th>\n",
       "      <td>2022-06-01 02:00:00</td>\n",
       "      <td>3487.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>False</td>\n",
       "      <td>Summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161770</th>\n",
       "      <td>2022-06-01 03:00:00</td>\n",
       "      <td>3693.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>False</td>\n",
       "      <td>Summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161771</th>\n",
       "      <td>2022-06-01 04:00:00</td>\n",
       "      <td>3694.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>False</td>\n",
       "      <td>Summer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "c9ac0cccacf4c80c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T13:19:23.340863Z",
     "start_time": "2025-12-07T13:19:23.331749Z"
    }
   },
   "source": [
    "# Data quality check and outlier detection\n",
    "print(\"Data Quality Analysis:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check for missing values\n",
    "missing_count = df['y'].isna().sum()\n",
    "print(f\"Missing values: {missing_count}\")\n",
    "\n",
    "# Check for negative values (shouldn't exist for solar generation)\n",
    "negative_count = (df['y'] < 0).sum()\n",
    "print(f\"Negative values: {negative_count}\")\n",
    "\n",
    "# Detect outliers using IQR method\n",
    "Q1 = df['y'].quantile(0.25)\n",
    "Q3 = df['y'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 3 * IQR  # 3*IQR for extreme outliers\n",
    "upper_bound = Q3 + 3 * IQR\n",
    "\n",
    "outliers = ((df['y'] < lower_bound) | (df['y'] > upper_bound)).sum()\n",
    "print(f\"Outliers detected (3*IQR method): {outliers}\")\n",
    "\n",
    "# Show basic statistics\n",
    "print(f\"\\nGeneration statistics:\")\n",
    "print(f\"  Min: {df['y'].min():.2f} MWh\")\n",
    "print(f\"  Max: {df['y'].max():.2f} MWh\")\n",
    "print(f\"  Mean: {df['y'].mean():.2f} MWh\")\n",
    "print(f\"  Median: {df['y'].median():.2f} MWh\")\n",
    "print(f\"  Std: {df['y'].std():.2f} MWh\")\n",
    "print(f\"  95th percentile: {df['y'].quantile(0.95):.2f} MWh\")\n",
    "print(f\"  99th percentile: {df['y'].quantile(0.99):.2f} MWh\")\n",
    "\n",
    "# Cap extreme outliers to reasonable maximum\n",
    "df_cleaned = df.copy()\n",
    "max_reasonable = df['y'].quantile(0.99) * 1.1  # 110% of 99th percentile\n",
    "df_cleaned.loc[df_cleaned['y'] > max_reasonable, 'y'] = max_reasonable\n",
    "df_cleaned.loc[df_cleaned['y'] < 0, 'y'] = 0  # Remove any negative values\n",
    "\n",
    "capped_count = (df['y'] != df_cleaned['y']).sum()\n",
    "print(f\"\\nCapped {capped_count} extreme values to max: {max_reasonable:.2f} MWh\")\n",
    "print(\"Data is ready for modeling\")\n",
    "\n",
    "# Update df with cleaned data\n",
    "df = df_cleaned"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Quality Analysis:\n",
      "============================================================\n",
      "Missing values: 0\n",
      "Negative values: 0\n",
      "Outliers detected (3*IQR method): 0\n",
      "\n",
      "Generation statistics:\n",
      "  Min: 190.00 MWh\n",
      "  Max: 20718.00 MWh\n",
      "  Mean: 7062.48 MWh\n",
      "  Median: 6421.00 MWh\n",
      "  Std: 3971.46 MWh\n",
      "  95th percentile: 14515.80 MWh\n",
      "  99th percentile: 17296.48 MWh\n",
      "\n",
      "Capped 16 extreme values to max: 19026.13 MWh\n",
      "Data is ready for modeling\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "711fe09b782eefc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T13:19:23.368309Z",
     "start_time": "2025-12-07T13:19:23.344868Z"
    }
   },
   "source": [
    "wind_df = pd.read_csv(\"../Gen_data/Wind_2022_2024.csv\")\n",
    "wind_df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              hourly__time  hourly__apparent_temperature  \\\n",
       "0      2022-01-01 00:00:00                           1.7   \n",
       "1      2022-01-01 01:00:00                           0.9   \n",
       "2      2022-01-01 02:00:00                           0.6   \n",
       "3      2022-01-01 03:00:00                           0.1   \n",
       "4      2022-01-01 04:00:00                          -0.9   \n",
       "...                    ...                           ...   \n",
       "26299  2024-12-31 19:00:00                          -1.2   \n",
       "26300  2024-12-31 20:00:00                          -2.3   \n",
       "26301  2024-12-31 21:00:00                          -3.0   \n",
       "26302  2024-12-31 22:00:00                          -3.0   \n",
       "26303  2024-12-31 23:00:00                          -3.2   \n",
       "\n",
       "       hourly__wind_speed_100m hourly__weather_code  cloud_cover  \\\n",
       "0                         15.5            Clear sky            1   \n",
       "1                         16.5            Clear sky            8   \n",
       "2                         17.0            Clear sky            4   \n",
       "3                         17.2            Clear sky            5   \n",
       "4                         16.1            Clear sky            3   \n",
       "...                        ...                  ...          ...   \n",
       "26299                      2.5            Clear sky            0   \n",
       "26300                      6.0            Clear sky            1   \n",
       "26301                      6.6            Clear sky            0   \n",
       "26302                      7.2            Clear sky            0   \n",
       "26303                      9.3            Clear sky            8   \n",
       "\n",
       "       precipitation  \n",
       "0                0.0  \n",
       "1                0.0  \n",
       "2                0.0  \n",
       "3                0.0  \n",
       "4                0.0  \n",
       "...              ...  \n",
       "26299            0.0  \n",
       "26300            0.0  \n",
       "26301            0.0  \n",
       "26302            0.0  \n",
       "26303            0.0  \n",
       "\n",
       "[26304 rows x 6 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hourly__time</th>\n",
       "      <th>hourly__apparent_temperature</th>\n",
       "      <th>hourly__wind_speed_100m</th>\n",
       "      <th>hourly__weather_code</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>precipitation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>1.7</td>\n",
       "      <td>15.5</td>\n",
       "      <td>Clear sky</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01 01:00:00</td>\n",
       "      <td>0.9</td>\n",
       "      <td>16.5</td>\n",
       "      <td>Clear sky</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01 02:00:00</td>\n",
       "      <td>0.6</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Clear sky</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01 03:00:00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>17.2</td>\n",
       "      <td>Clear sky</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01 04:00:00</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>16.1</td>\n",
       "      <td>Clear sky</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26299</th>\n",
       "      <td>2024-12-31 19:00:00</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Clear sky</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26300</th>\n",
       "      <td>2024-12-31 20:00:00</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Clear sky</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26301</th>\n",
       "      <td>2024-12-31 21:00:00</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>Clear sky</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26302</th>\n",
       "      <td>2024-12-31 22:00:00</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>Clear sky</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26303</th>\n",
       "      <td>2024-12-31 23:00:00</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>9.3</td>\n",
       "      <td>Clear sky</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26304 rows × 6 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "8b7cb3e9baa81e3c",
   "metadata": {},
   "source": [
    "## add_wind_regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "1bd24c451715ffad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T13:19:26.764283Z",
     "start_time": "2025-12-07T13:19:23.373316Z"
    }
   },
   "source": [
    "# Split data into train (70%), validation (20%), and test (10%)\n",
    "# Using only March to September data from 2022-2024\n",
    "from src.LSTM import create_advanced_features\n",
    "total_rows = len(df)\n",
    "train_size = int(0.7 * total_rows)\n",
    "val_size = int(0.2 * total_rows)\n",
    "\n",
    "df = create_advanced_features(df)\n",
    "train_df = df.iloc[:train_size].copy()\n",
    "val_df = df.iloc[train_size:train_size + val_size].copy()\n",
    "test_df = df.iloc[train_size + val_size:].copy()\n",
    "\n",
    "def add_wind_regressor(df, wind_df):\n",
    "    df['ds'] = pd.to_datetime(df['ds'])\n",
    "    wind_df['hourly__time'] = pd.to_datetime(wind_df['hourly__time'])\n",
    "\n",
    "    merged = pd.merge_asof(\n",
    "        df.sort_values('ds'),\n",
    "        wind_df.sort_values('hourly__time'),\n",
    "        left_on='ds',\n",
    "        right_on='hourly__time',\n",
    "        direction='nearest',\n",
    "        tolerance=pd.Timedelta('30min')\n",
    "    )\n",
    "\n",
    "    # Time\n",
    "    merged['hour'] = merged['ds'].dt.hour\n",
    "    merged['month'] = merged['ds'].dt.month\n",
    "\n",
    "    # wind_direction\n",
    "    wind_dir_rad = np.deg2rad(merged['hourly__wind_direction_100m'])\n",
    "    merged['wind_direction_sin'] = np.sin(wind_dir_rad)\n",
    "    merged['wind_direction_cos'] = np.cos(wind_dir_rad)\n",
    "\n",
    "    '''\n",
    "    # On average across Spain:\n",
    "    # Wind energy is stronger in spring (March to May) and winter (November to February)\n",
    "    # Weaker in summer (June to August).\n",
    "    merged['season_factor'] = (\n",
    "        0.5 * (np.cos((merged['month'] - 2) / 12 * 2 * np.pi) ** 2) +\n",
    "        0.5 * (np.cos((merged['month'] - 12) / 12 * 2 * np.pi) ** 2)\n",
    "    )\n",
    "    # unified to [0,1]\n",
    "    merged['season_factor'] = (merged['season_factor'] - merged['season_factor'].min()) / \\\n",
    "                              (merged['season_factor'].max() - merged['season_factor'].min())\n",
    "    '''\n",
    "    # 使用更符合西班牙风能分布的季节因子\n",
    "    def calculate_season_factor(month):\n",
    "        # 根据西班牙地理条件调整\n",
    "        if month in [12, 1, 2]:  # 冬春季节风能较强\n",
    "            return 1\n",
    "        elif month in [3, 4, 5]:  # 夏季风能较弱\n",
    "            return 0.8\n",
    "        else:\n",
    "            return 0.6\n",
    "\n",
    "    merged['season_factor'] = merged['month'].apply(calculate_season_factor)\n",
    "\n",
    "\n",
    "    merged['wind_potential_index'] = (\n",
    "        merged['hourly__wind_speed_100m'] * merged['season_factor']\n",
    "    )\n",
    "\n",
    "    return merged\n",
    "\n",
    "train_df = add_wind_regressor(train_df, wind_df)\n",
    "val_df = add_wind_regressor(val_df, wind_df)\n",
    "test_df = add_wind_regressor(test_df, wind_df)\n",
    "\n",
    "print(f\"Dataset: March to September (2022-2024)\")\n",
    "print(f\"Total data points: {total_rows}\")\n",
    "print(f\"\\nTraining set: {len(train_df)} records ({len(train_df)/total_rows*100:.1f}%)\")\n",
    "print(f\"  Period: {train_df['ds'].min()} to {train_df['ds'].max()}\")\n",
    "print(f\"\\nValidation set: {len(val_df)} records ({len(val_df)/total_rows*100:.1f}%)\")\n",
    "print(f\"  Period: {val_df['ds'].min()} to {val_df['ds'].max()}\")\n",
    "print(f\"\\nTest set: {len(test_df)} records ({len(test_df)/total_rows*100:.1f}%)\")\n",
    "print(f\"  Period: {test_df['ds'].min()} to {test_df['ds'].max()}\")\n",
    "\n",
    "# Show wind data by hour\n",
    "print(f\"\\nWind Pattern (sample):\")\n",
    "hourly_elevation = train_df.groupby('hour')['wind_potential_index'].mean().reset_index()\n",
    "for _, row in hourly_elevation.iterrows():\n",
    "    print(f\"  Hour {int(row['hour']):02d}:00 - wind_potential_index: {row['wind_potential_index']:.3f}\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\202510\\2025-26-Data-driven\\src\\LSTM.py:90: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.fillna(method=\"ffill\").fillna(method=\"bfill\")\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'hourly__wind_direction_100m'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3804\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3805\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[0;32m   3806\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32mindex.pyx:167\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mindex.pyx:196\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'hourly__wind_direction_100m'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 66\u001B[0m\n\u001B[0;32m     60\u001B[0m     merged[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwind_potential_index\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     61\u001B[0m         merged[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhourly__wind_speed_100m\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m*\u001B[39m merged[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mseason_factor\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m     62\u001B[0m     )\n\u001B[0;32m     64\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m merged\n\u001B[1;32m---> 66\u001B[0m train_df \u001B[38;5;241m=\u001B[39m add_wind_regressor(train_df, wind_df)\n\u001B[0;32m     67\u001B[0m val_df \u001B[38;5;241m=\u001B[39m add_wind_regressor(val_df, wind_df)\n\u001B[0;32m     68\u001B[0m test_df \u001B[38;5;241m=\u001B[39m add_wind_regressor(test_df, wind_df)\n",
      "Cell \u001B[1;32mIn[6], line 31\u001B[0m, in \u001B[0;36madd_wind_regressor\u001B[1;34m(df, wind_df)\u001B[0m\n\u001B[0;32m     28\u001B[0m merged[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmonth\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m merged[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mds\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mdt\u001B[38;5;241m.\u001B[39mmonth\n\u001B[0;32m     30\u001B[0m \u001B[38;5;66;03m# wind_direction\u001B[39;00m\n\u001B[1;32m---> 31\u001B[0m wind_dir_rad \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mdeg2rad(merged[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhourly__wind_direction_100m\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m     32\u001B[0m merged[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwind_direction_sin\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39msin(wind_dir_rad)\n\u001B[0;32m     33\u001B[0m merged[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwind_direction_cos\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mcos(wind_dir_rad)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   4100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   4101\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[1;32m-> 4102\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mget_loc(key)\n\u001B[0;32m   4103\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[0;32m   4104\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3807\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[0;32m   3808\u001B[0m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc\u001B[38;5;241m.\u001B[39mIterable)\n\u001B[0;32m   3809\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[0;32m   3810\u001B[0m     ):\n\u001B[0;32m   3811\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[1;32m-> 3812\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3813\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3814\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3815\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3816\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m   3817\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'hourly__wind_direction_100m'"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "18f7b3a9fc4a0ec2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T13:19:26.772279100Z",
     "start_time": "2025-12-04T11:02:48.139333Z"
    }
   },
   "source": [
    "train_df.describe"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of                       ds        y  year  month  day  is_weekend  hour  \\\n",
       "0    2022-01-01 00:00:00   6342.0  2022      1    1        True     0   \n",
       "1    2022-01-01 01:00:00   6398.0  2022      1    1        True     1   \n",
       "2    2022-01-01 02:00:00   6456.0  2022      1    1        True     2   \n",
       "3    2022-01-01 03:00:00   6144.0  2022      1    1        True     3   \n",
       "4    2022-01-01 04:00:00   5943.0  2022      1    1        True     4   \n",
       "...                  ...      ...   ...    ...  ...         ...   ...   \n",
       "9132 2024-01-19 14:00:00  13766.0  2024      1   19       False    14   \n",
       "9133 2024-01-19 15:00:00  13403.0  2024      1   19       False    15   \n",
       "9134 2024-01-19 16:00:00  13483.0  2024      1   19       False    16   \n",
       "9135 2024-01-19 17:00:00  12931.0  2024      1   19       False    17   \n",
       "9136 2024-01-19 18:00:00  12353.0  2024      1   19       False    18   \n",
       "\n",
       "      dayofweek  dayofyear  hour_sin  ...  y_lag48        hourly__time  \\\n",
       "0             5          1  0.000000  ...   6342.0 2022-01-01 00:00:00   \n",
       "1             5          1  0.258819  ...   6342.0 2022-01-01 01:00:00   \n",
       "2             5          1  0.500000  ...   6342.0 2022-01-01 02:00:00   \n",
       "3             5          1  0.707107  ...   6342.0 2022-01-01 03:00:00   \n",
       "4             5          1  0.866025  ...   6342.0 2022-01-01 04:00:00   \n",
       "...         ...        ...       ...  ...      ...                 ...   \n",
       "9132          4         19 -0.500000  ...  18510.0 2024-01-19 14:00:00   \n",
       "9133          4         19 -0.707107  ...  18519.0 2024-01-19 15:00:00   \n",
       "9134          4         19 -0.866025  ...  18188.0 2024-01-19 16:00:00   \n",
       "9135          4         19 -0.965926  ...  17797.0 2024-01-19 17:00:00   \n",
       "9136          4         19 -1.000000  ...  18928.0 2024-01-19 18:00:00   \n",
       "\n",
       "      hourly__apparent_temperature  hourly__wind_speed_100m  \\\n",
       "0                              5.2                      9.5   \n",
       "1                              4.2                     10.0   \n",
       "2                              3.6                     10.7   \n",
       "3                              3.5                     11.1   \n",
       "4                              3.8                     12.9   \n",
       "...                            ...                      ...   \n",
       "9132                           7.2                     11.8   \n",
       "9133                           7.2                     11.3   \n",
       "9134                           6.6                     12.0   \n",
       "9135                           6.5                     10.8   \n",
       "9136                           6.0                     13.0   \n",
       "\n",
       "      hourly__wind_direction_100m  daily__weather_code  wind_direction_sin  \\\n",
       "0                             279        Partly cloudy           -0.987688   \n",
       "1                             283             Overcast           -0.974370   \n",
       "2                             282             Overcast           -0.978148   \n",
       "3                             299        Light drizzle           -0.874620   \n",
       "4                             306          Slight rain           -0.809017   \n",
       "...                           ...                  ...                 ...   \n",
       "9132                          110                  NaN            0.939693   \n",
       "9133                          107                  NaN            0.956305   \n",
       "9134                           99                  NaN            0.987688   \n",
       "9135                           88                  NaN            0.999391   \n",
       "9136                           93                  NaN            0.998630   \n",
       "\n",
       "      wind_direction_cos  season_factor  wind_potential_index  \n",
       "0               0.156434            1.0                   9.5  \n",
       "1               0.224951            1.0                  10.0  \n",
       "2               0.207912            1.0                  10.7  \n",
       "3               0.484810            1.0                  11.1  \n",
       "4               0.587785            1.0                  12.9  \n",
       "...                  ...            ...                   ...  \n",
       "9132           -0.342020            1.0                  11.8  \n",
       "9133           -0.292372            1.0                  11.3  \n",
       "9134           -0.156434            1.0                  12.0  \n",
       "9135            0.034899            1.0                  10.8  \n",
       "9136           -0.052336            1.0                  13.0  \n",
       "\n",
       "[9137 rows x 34 columns]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "6ec7142b844c34fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T13:19:26.772279100Z",
     "start_time": "2025-12-04T11:02:48.165580Z"
    }
   },
   "source": [
    "from src.random_forest import RandomForestModel\n",
    "from src.lightgbm import LightGBM\n",
    "from src.LSTM import LSTM\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# model = RandomForestModel()\n",
    "model = LSTM()\n",
    "\n",
    "train_df['floor'] = 0\n",
    "\n",
    "print(\"Training Model for wind power forecasting...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "model.fit(train_df)\n",
    "\n",
    "print(\"\\nTraining complete!\")\n",
    "print(\"=\" * 60)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model for wind power forecasting...\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'select_dtypes'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 14\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTraining Model for wind power forecasting...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m=\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m60\u001B[39m)\n\u001B[1;32m---> 14\u001B[0m model\u001B[38;5;241m.\u001B[39mfit(train_df)\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mTraining complete!\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m=\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m60\u001B[39m)\n",
      "File \u001B[1;32mE:\\202510\\2025-26-Data-driven\\src\\LSTM.py:163\u001B[0m, in \u001B[0;36mLSTM.fit\u001B[1;34m(self, df, target_col, epochs, lr, batch)\u001B[0m\n\u001B[0;32m    160\u001B[0m y \u001B[38;5;241m=\u001B[39m df[target_col]\u001B[38;5;241m.\u001B[39mvalues\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    162\u001B[0m \u001B[38;5;66;03m# Remove datetime columns\u001B[39;00m\n\u001B[1;32m--> 163\u001B[0m datetime_cols \u001B[38;5;241m=\u001B[39m X\u001B[38;5;241m.\u001B[39mselect_dtypes(include\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdatetime64[ns]\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdatetime64[ns, UTC]\u001B[39m\u001B[38;5;124m'\u001B[39m])\u001B[38;5;241m.\u001B[39mcolumns\n\u001B[0;32m    164\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(datetime_cols) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    165\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[Warning] Dropping datetime columns: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlist\u001B[39m(datetime_cols)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'numpy.ndarray' object has no attribute 'select_dtypes'"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "dcf38d15fb52736c",
   "metadata": {},
   "source": [
    "# Validate model on validation set\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "val_df_pred = val_df.copy()\n",
    "val_df_pred['floor'] = 0\n",
    "val_forecast = model.predict(val_df_pred)\n",
    "\n",
    "# Clip predictions to non-negative values (safety check)\n",
    "val_forecast['yhat'] = val_forecast['yhat'].clip(lower=0)\n",
    "\n",
    "# Reset indices to align properly\n",
    "val_actual = val_df['y'].values\n",
    "val_pred = val_forecast['yhat'].values\n",
    "\n",
    "# Calculate validation metrics\n",
    "val_mae = mean_absolute_error(val_actual, val_pred)\n",
    "val_rmse = np.sqrt(mean_squared_error(val_actual, val_pred))\n",
    "\n",
    "# Calculate MAPE excluding very small values (< 10 MWh threshold for meaningful generation)\n",
    "# This filters out nighttime and very low generation periods\n",
    "threshold = 1000  # MWh\n",
    "significant_mask = val_actual >= threshold\n",
    "if significant_mask.sum() > 0:\n",
    "    val_mape = np.mean(np.abs((val_actual[significant_mask] - val_pred[significant_mask]) / val_actual[significant_mask])) * 100\n",
    "else:\n",
    "    val_mape = np.nan\n",
    "\n",
    "print(\"Validation Set Performance:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"MAE:  {val_mae:.2f} MWh\")\n",
    "print(f\"RMSE: {val_rmse:.2f} MWh\")\n",
    "if not np.isnan(val_mape):\n",
    "    print(f\"MAPE (generation >= {threshold} MWh): {val_mape:.2f}%\")\n",
    "else:\n",
    "    print(f\"MAPE: N/A\")\n",
    "\n",
    "# Show additional info\n",
    "zero_count = (val_actual == 0).sum()\n",
    "low_gen_count = ((val_actual > 0) & (val_actual < threshold)).sum()\n",
    "print(f\"\\nData distribution in validation set:\")\n",
    "print(f\"  Zero values: {zero_count} ({zero_count/len(val_actual)*100:.1f}%)\")\n",
    "print(f\"  Low generation (0-{threshold} MWh): {low_gen_count} ({low_gen_count/len(val_actual)*100:.1f}%)\")\n",
    "print(f\"  Significant generation (>={threshold} MWh): {significant_mask.sum()} ({significant_mask.sum()/len(val_actual)*100:.1f}%)\")\n",
    "\n",
    "# Check prediction range\n",
    "print(f\"\\nPrediction range:\")\n",
    "print(f\"  Min: {val_pred.min():.2f} MWh\")\n",
    "print(f\"  Max: {val_pred.max():.2f} MWh\")\n",
    "print(f\"  Mean: {val_pred.mean():.2f} MWh\")\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "af5543cebb6a81f2",
   "metadata": {},
   "source": [
    "print(\"=== Check MAE inputs ===\")\n",
    "print(\"val_actual NaN:\", np.isnan(val_actual).sum())\n",
    "print(\"val_pred NaN:\", np.isnan(val_pred).sum())\n",
    "\n",
    "print(\"\\n=== Check Inf ===\")\n",
    "print(\"val_actual Inf:\", np.isinf(val_actual).sum())\n",
    "print(\"val_pred Inf:\", np.isinf(val_pred).sum())\n",
    "\n",
    "print(\"\\n=== First 10 values ===\")\n",
    "print(\"val_actual[:10]:\", val_actual[:10])\n",
    "print(\"val_pred[:10]:\", val_pred[:10])\n",
    "\n",
    "print(\"\\n=== val_forecast NaN summary ===\")\n",
    "print(val_forecast.isna().sum())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cba939d28535bd56",
   "metadata": {},
   "source": [
    "# Test model on test set\n",
    "test_df_pred = test_df.copy()\n",
    "test_df_pred['floor'] = 0\n",
    "test_forecast = model.predict(test_df_pred)\n",
    "\n",
    "# Clip predictions to non-negative values (safety check)\n",
    "test_forecast['yhat'] = test_forecast['yhat'].clip(lower=0)\n",
    "\n",
    "# Reset indices to align properly\n",
    "test_actual = test_df['y'].values\n",
    "test_pred = test_forecast['yhat'].values\n",
    "\n",
    "# Calculate test metrics\n",
    "test_mae = mean_absolute_error(test_actual, test_pred)\n",
    "test_rmse = np.sqrt(mean_squared_error(test_actual, test_pred))\n",
    "\n",
    "# Calculate MAPE excluding very small values (< 10 MWh threshold)\n",
    "threshold = 1000  # MWh\n",
    "significant_mask = test_actual >= threshold\n",
    "if significant_mask.sum() > 0:\n",
    "    test_mape = np.mean(np.abs((test_actual[significant_mask] - test_pred[significant_mask]) / test_actual[significant_mask])) * 100\n",
    "else:\n",
    "    test_mape = np.nan\n",
    "\n",
    "print(\"Test Set Performance:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"MAE:  {test_mae:.2f} MWh\")\n",
    "print(f\"RMSE: {test_rmse:.2f} MWh\")\n",
    "if not np.isnan(test_mape):\n",
    "    print(f\"MAPE (generation >= {threshold} MWh): {test_mape:.2f}%\")\n",
    "else:\n",
    "    print(f\"MAPE: N/A\")\n",
    "\n",
    "# Show additional info\n",
    "zero_count = (test_actual == 0).sum()\n",
    "low_gen_count = ((test_actual > 0) & (test_actual < threshold)).sum()\n",
    "print(f\"\\nData distribution in test set:\")\n",
    "print(f\"  Zero values: {zero_count} ({zero_count/len(test_actual)*100:.1f}%)\")\n",
    "print(f\"  Low generation (0-{threshold} MWh): {low_gen_count} ({low_gen_count/len(test_actual)*100:.1f}%)\")\n",
    "print(f\"  Significant generation (>={threshold} MWh): {significant_mask.sum()} ({significant_mask.sum()/len(test_actual)*100:.1f}%)\")\n",
    "\n",
    "# Check prediction range\n",
    "print(f\"\\nPrediction range:\")\n",
    "print(f\"  Min: {test_pred.min():.2f} MWh\")\n",
    "print(f\"  Max: {test_pred.max():.2f} MWh\")\n",
    "print(f\"  Mean: {test_pred.mean():.2f} MWh\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d97d6130d1d76c71",
   "metadata": {},
   "source": [
    "# Load actual 2025 data for comparison\n",
    "df_2025 = pd.read_csv(\"../Gen_data/Wind_Onshore_hourly_2025.csv\")\n",
    "df_2025['ds'] = pd.to_datetime(df_2025['datetime'])\n",
    "df_2025['y'] = df_2025['Generation (MWh)']\n",
    "df_2025"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "175bb949b9f18415",
   "metadata": {},
   "source": [
    "## Predict 2025"
   ]
  },
  {
   "cell_type": "code",
   "id": "db1b9a8e433ec3a3",
   "metadata": {},
   "source": [
    "df_2025['month'] = df_2025['ds'].dt.month\n",
    "df_2025 = df_2025[(df_2025['month'] >= 1) & (df_2025['month'] <= 6)].copy()\n",
    "\n",
    "wind_df1 = pd.read_csv(\"../Gen_data/Wind_2025_1.csv\")\n",
    "# Create future dataframe with regressor\n",
    "future_2025 = df_2025[['ds']].copy()\n",
    "future_2025['floor'] = 0\n",
    "future_2025 = add_wind_regressor(future_2025,wind_df1)\n",
    "\n",
    "future_2025['year'] = future_2025['ds'].dt.year\n",
    "future_2025['day'] = future_2025['ds'].dt.day\n",
    "future_2025['weekday'] = future_2025['ds'].dt.day_name()  # weekdays\n",
    "future_2025['is_weekend'] = future_2025['ds'].dt.dayofweek >= 5  # True = weekends\n",
    "future_2025['season'] = future_2025['month'].apply(get_season)\n",
    "future_2025 = future_2025.drop('hourly__time', axis=1)\n",
    "\n",
    "future_2025.describe"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "50f5778d93de5f38",
   "metadata": {},
   "source": [
    "def align_columns(train_df, future_df):\n",
    "    \"\"\"\n",
    "    强制让 future_df 的列与 train_df 完全对齐（包含顺序）。\n",
    "    1. 补齐 future_df 中缺失的列（按 train_df 类型）\n",
    "    2. 删除多余列\n",
    "    3. 严格按 train_df 列顺序排序\n",
    "    \"\"\"\n",
    "\n",
    "    train_cols = train_df.columns\n",
    "    future_cols = future_df.columns\n",
    "\n",
    "    # -------- 1. 添加缺失列 --------\n",
    "    missing_cols = [c for c in train_cols if c not in future_cols]\n",
    "    for col in missing_cols:\n",
    "        # 按训练集的 dtype 创建默认值\n",
    "        if train_df[col].dtype == 'object':\n",
    "            future_df[col] = 'Unknown'\n",
    "        elif train_df[col].dtype == 'bool':\n",
    "            future_df[col] = False\n",
    "        else:\n",
    "            future_df[col] = 0\n",
    "\n",
    "    # -------- 2. 删除 future 有但 train 没有的列 --------\n",
    "    extra_cols = [c for c in future_cols if c not in train_cols]\n",
    "    if extra_cols:\n",
    "        future_df = future_df.drop(columns=extra_cols)\n",
    "\n",
    "    # -------- 3. 按 train_df 的顺序重新排列 --------\n",
    "    future_df = future_df[train_cols]\n",
    "\n",
    "    return future_df\n",
    "\n",
    "future_2025 = align_columns(train_df, future_2025)\n",
    "future_2025"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c6ffefb9fff90a67",
   "metadata": {},
   "source": [
    "train_df.dtypes"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e93eeed3712373c8",
   "metadata": {},
   "source": [
    "# Make predictions\n",
    "forecast_2025 = model.predict(future_2025)\n",
    "forecast_2025"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e541b134605a6b28",
   "metadata": {},
   "source": [
    "\n",
    "# Make predictions\n",
    "forecast_2025 = model.predict(future_2025)\n",
    "\n",
    "# Clip predictions to non-negative values\n",
    "forecast_2025['yhat'] = forecast_2025['yhat'].clip(lower=0)\n",
    "forecast_2025['yhat'] = forecast_2025['yhat'].clip(lower=0)\n",
    "\n",
    "# Calculate metrics for 2025 forecast\n",
    "actual_2025 = df_2025['y'].values\n",
    "pred_2025 = forecast_2025['yhat'].values\n",
    "\n",
    "mae_2025 = mean_absolute_error(actual_2025, pred_2025)\n",
    "rmse_2025 = np.sqrt(mean_squared_error(actual_2025, pred_2025))\n",
    "mape_2025 = np.mean(np.abs((actual_2025 - pred_2025) / (actual_2025 + 1e-8))) * 100\n",
    "\n",
    "print(f\"2025 Forecast Performance (March-September): MAE={mae_2025:.2f} MWh, RMSE={rmse_2025:.2f} MWh, MAPE={mape_2025:.2f}%\")\n",
    "\n",
    "forecast_2025"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "237d8bf3d189ff72",
   "metadata": {},
   "source": [
    "\n",
    "# Analyze hourly patterns with wind potential for 2025 forecast\n",
    "df_2025['hour'] = df_2025['ds'].dt.hour\n",
    "forecast_2025_merged = forecast_2025[['ds', 'yhat']].copy()\n",
    "forecast_2025_merged['hour'] = forecast_2025_merged['ds'].dt.hour\n",
    "\n",
    "hourly_stats = df_2025.groupby('hour')['y'].agg(['mean', 'std', 'min', 'max'])\n",
    "hourly_pred = forecast_2025_merged.groupby('hour')['yhat'].mean()\n",
    "hourly_wind = future_2025.groupby(future_2025['ds'].dt.hour)['wind_potential_index'].mean()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Hourly Statistics (March-September 2025 Forecast):\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Hour':<6} {'Actual':>10} {'Predicted':>10} {'Wind Potential':>12} {'Status':>15}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for hour in range(24):\n",
    "    actual_mean = hourly_stats.loc[hour, 'mean'] if hour in hourly_stats.index else 0\n",
    "    pred_mean = hourly_pred.loc[hour] if hour in hourly_pred.index else 0\n",
    "    wind_potential = hourly_wind.loc[hour] if hour in hourly_wind.index else 0\n",
    "\n",
    "    # Categorize based on wind potential\n",
    "    if wind_potential < 10:\n",
    "        status = \"Low Wind\"\n",
    "    elif wind_potential < 12:\n",
    "        status = \"Moderate Wind\"\n",
    "    else:\n",
    "        status = \"High Wind\"\n",
    "\n",
    "    print(f\"{hour:02d}:00  {actual_mean:>10.2f} {pred_mean:>10.2f} {wind_potential:>12.3f} {status:>15}\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Note: Wind potential index combines wind speed and seasonal factors for\")\n",
    "print(\"      more accurate wind power generation forecasting.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "30ddeea552200eb4",
   "metadata": {},
   "source": [
    "# Visualize train/val/test splits and model performance for wind power\n",
    "fig, axes = plt.subplots(2, 1, figsize=(20, 12))\n",
    "\n",
    "# Plot 1: Historical data with splits (Mar-Sep 2022-2024)\n",
    "ax1 = axes[0]\n",
    "ax1.plot(train_df['ds'], train_df['y'], 'b.', label='Training Data', alpha=0.5, markersize=2)\n",
    "ax1.plot(val_df['ds'], val_df['y'], 'g.', label='Validation Data', alpha=0.5, markersize=2)\n",
    "ax1.plot(test_df['ds'], test_df['y'], 'orange', label='Test Data', alpha=0.5, markersize=2)\n",
    "\n",
    "# Add predictions on validation and test sets\n",
    "ax1.plot(val_forecast['ds'], val_forecast['yhat'], 'g-', label='Validation Forecast', linewidth=2, alpha=0.7)\n",
    "ax1.plot(test_forecast['ds'], test_forecast['yhat'], 'r-', label='Test Forecast', linewidth=2, alpha=0.7)\n",
    "\n",
    "ax1.set_title('Historical Wind Power Data: Train/Validation/Test Splits (2022-2024)', fontsize=14)\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Generation (MWh)')\n",
    "ax1.legend(loc='upper right')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: 2025 Forecast (Mar-Sep)\n",
    "ax2 = axes[1]\n",
    "ax2.plot(df_2025['ds'], df_2025['y'], 'blue', label='Actual 2025 Data', linewidth=1, alpha=0.7)\n",
    "ax2.plot(forecast_2025['ds'], forecast_2025['yhat'], 'lightcoral', label='2025 Wind Power Forecast', linewidth=2)\n",
    "\n",
    "ax2.set_title('Wind Power Generation Forecast 2025 - LSTM', fontsize=14)\n",
    "ax2.set_xlabel('Date')\n",
    "ax2.set_ylabel('Generation (MWh)')\n",
    "ax2.legend(loc='upper right')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c0922618cb99fb8",
   "metadata": {},
   "source": [
    "# Graph 1"
   ]
  },
  {
   "cell_type": "code",
   "id": "2dee847e969536c1",
   "metadata": {},
   "source": [
    "# Export 2025 forecast (Mar-Sep) to CSV\n",
    "forecast_export = forecast_2025[['ds', 'yhat']].copy()\n",
    "forecast_export['timestamp'] = forecast_export['ds'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "forecast_export = forecast_export[['timestamp', 'yhat']].rename(columns={\n",
    "    'timestamp': 'Timestamp',\n",
    "    'yhat': 'Forecast_Generation_MWh'\n",
    "})\n",
    "\n",
    "output_file = 'wind_forecast_2025_LSTM.csv'\n",
    "forecast_export.to_csv(output_file, index=False)\n",
    "print(f\"2025 forecast (March to September) exported to: {output_file}\")\n",
    "print(f\"\\nSummary statistics of 2025 Mar-Sep forecast:\")\n",
    "print(forecast_export.describe())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b1dd706afe1e5d92",
   "metadata": {},
   "source": [
    "# Load actual 2025 data for comparison\n",
    "df_2025 = pd.read_csv(\"../Gen_data/Wind_Onshore_hourly_2025.csv\")\n",
    "df_2025['ds'] = pd.to_datetime(df_2025['datetime'])\n",
    "df_2025['y'] = df_2025['Generation (MWh)']\n",
    "\n",
    "# 删除datetime列中2025/10/21 21:00:00之后的所有数据行\n",
    "cutoff_datetime = pd.to_datetime('2025-10-21 20:00:00')\n",
    "df_2025 = df_2025[df_2025['ds'] <= cutoff_datetime]\n",
    "\n",
    "df_2025"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ee2a74c4ed05b4d5",
   "metadata": {},
   "source": [
    "# Process 2025 data similar to training data\n",
    "# The datetime column should already be in the correct format\n",
    "df_2025['ds'] = pd.to_datetime(df_2025['datetime'])\n",
    "df_2025['y'] = df_2025['Generation (MWh)']\n",
    "df_2025 = df_2025[['ds', 'y']].sort_values('ds')\n",
    "\n",
    "# Filter for March to September 2025 only\n",
    "df_2025['month'] = df_2025['ds'].dt.month\n",
    "df_2025 = df_2025[(df_2025['month'] >= 3) & (df_2025['month'] <= 9)].copy()\n",
    "df_2025 = df_2025[['ds', 'y']]  # Keep only required columns\n",
    "\n",
    "print(f\"2025 actual data loaded (March to September):\")\n",
    "print(f\"  Period: {df_2025['ds'].min()} to {df_2025['ds'].max()}\")\n",
    "print(f\"  Total records: {len(df_2025)}\")\n",
    "print(f\"  Data range: {df_2025['y'].min():.2f} to {df_2025['y'].max():.2f} MWh\")\n",
    "\n",
    "# Merge forecast with actual 2025 data (both are hourly)\n",
    "comparison = pd.merge(\n",
    "    forecast_2025[['ds', 'yhat']],\n",
    "    df_2025[['ds', 'y']],\n",
    "    on='ds',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "print(f\"\\nMatched records: {len(comparison)}\")\n",
    "\n",
    "# Calculate metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "mae = mean_absolute_error(comparison['y'], comparison['yhat'])\n",
    "rmse = np.sqrt(mean_squared_error(comparison['y'], comparison['yhat']))\n",
    "\n",
    "# Calculate MAPE excluding very small values\n",
    "threshold = 1000  # MWh\n",
    "significant_mask = comparison['y'] >= threshold\n",
    "if significant_mask.sum() > 0:\n",
    "    mape = np.mean(np.abs((comparison['y'][significant_mask] - comparison['yhat'][significant_mask]) / comparison['y'][significant_mask])) * 100\n",
    "else:\n",
    "    mape = np.nan\n",
    "\n",
    "print(f\"\\n2025 Forecast Performance Metrics:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"MAE:  {mae:.2f} MWh\")\n",
    "print(f\"RMSE: {rmse:.2f} MWh\")\n",
    "if not np.isnan(mape):\n",
    "    print(f\"MAPE (generation >= {threshold} MWh): {mape:.2f}%\")\n",
    "else:\n",
    "    print(f\"MAPE: N/A\")\n",
    "\n",
    "# Show data ranges\n",
    "print(f\"\\nData ranges:\")\n",
    "print(f\"  Actual values: {comparison['y'].min():.2f} to {comparison['y'].max():.2f} MWh\")\n",
    "print(f\"  Forecasted values: {comparison['yhat'].min():.2f} to {comparison['yhat'].max():.2f} MWh\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5f58ffda657a8362",
   "metadata": {},
   "source": [
    "# Check for zero values in actual data\n",
    "zero_counts = (comparison['y'] == 0).sum()\n",
    "print(f\"Number of zero values in actual data: {zero_counts}\")\n",
    "\n",
    "# Calculate metrics with handling for zero values\n",
    "mae = mean_absolute_error(comparison['y'], comparison['yhat'])\n",
    "rmse = np.sqrt(mean_squared_error(comparison['y'], comparison['yhat']))\n",
    "\n",
    "# Modified MAPE calculation excluding zero values\n",
    "non_zero_mask = comparison['y'] != 0\n",
    "mape = np.mean(np.abs((comparison['y'][non_zero_mask] - comparison['yhat'][non_zero_mask]) / comparison['y'][non_zero_mask])) * 100\n",
    "\n",
    "print(f\"\\nMetrics (excluding zero values for MAPE):\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f} MW\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "print(f\"Root Mean Square Error (RMSE): {rmse:.2f} MW\")\n",
    "\n",
    "# Show min/max values\n",
    "print(f\"\\nData ranges:\")\n",
    "print(f\"Actual values range: {comparison['y'].min():.2f} to {comparison['y'].max():.2f} MW\")\n",
    "print(f\"Forecasted values range: {comparison['yhat'].min():.2f} to {comparison['yhat'].max():.2f} MW\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8847a69bc047b1fa",
   "metadata": {},
   "source": [
    "# Add hour of day for filtering daylight hours\n",
    "comparison['hour'] = comparison['ds'].dt.hour\n",
    "\n",
    "# Calculate installed capacity (using 95th percentile of actual values as proxy)\n",
    "installed_capacity = comparison['y'].quantile(0.95)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9696b5d6b8db6f2c",
   "metadata": {},
   "source": [
    "# Create hourly averages for error analysis\n",
    "hourly_metrics = comparison.groupby('hour').agg({\n",
    "    'y': 'mean',\n",
    "    'yhat': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "hourly_metrics['mae'] = abs(hourly_metrics['y'] - hourly_metrics['yhat'])\n",
    "hourly_metrics['nmae'] = hourly_metrics['mae'] / installed_capacity * 100\n",
    "\n",
    "# Plot hourly performance\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(hourly_metrics['hour'], hourly_metrics['y'], 'b-', label='Average Actual')\n",
    "plt.plot(hourly_metrics['hour'], hourly_metrics['yhat'], 'r--', label='Average Forecast')\n",
    "plt.title('Average Daily Generation Profile - LSTM')\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Generation (MW)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(hourly_metrics['hour'], hourly_metrics['nmae'], alpha=0.6)\n",
    "plt.title('Normalized MAE by Hour - LSTM')\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('nMAE (% of installed capacity)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "190831f45ef3d1a5",
   "metadata": {},
   "source": [
    "# Graph 2"
   ]
  },
  {
   "cell_type": "code",
   "id": "f66bfd674284abcd",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
